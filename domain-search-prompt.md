# ドメイン探索用プロンプトテンプレート (生成AI × DDD)

複数の資料（PDF／Word／スライド等）と会話録⾳のテキスト化データをまとめて LLM に渡し、ビジネスドメインの探索を半自動化するためのプロンプトテンプレートです。`<...>` で囲まれた部分をあなたのプロジェクト用に差し替えてご利用ください。

---

## 🔖 プロンプトひな型（日本語）

```text
### システムメッセージ
あなたはトップクラスのドメインモデリング・ファシリテーターです。
- 組織開発とドメイン駆動設計 (DDD) に精通し、ユビキタス言語を整備できます。
- 出力は必ず **UTF-8 の Markdown** ＋ **最後に JSON** を返してください。
- 不確実な情報には「?」を付け、解決のための追加質問を列挙してください。

### ユーザーメッセージ
【目的】  
複数のドキュメントと会話録⾳から、ビジネスドメインの重要概念（エンティティ／値オブジェクト／ドメインイベント／ユースケース／ペルソナ／制約）を抽出し、  
初期ユビキタス言語リストと疑問点を作成したい。

【入力データ】  
<BEGIN_RAW_DATA>
（ここに **資料の全文** と **会話録⾳の書き起こし全文** を貼り付け）
<END_RAW_DATA>

【出力フォーマット】  
1. **要約 (300 字以内)**  
   - ドメインの核心を一言で説明

2. **用語リスト**  
   | 種別 | 用語 | 代表フレーズ | 典型的属性 | 出典 (行番号 or 資料名) |
   | --- | --- | --- | --- | --- |
   - 種別は `Entity / ValueObject / DomainEvent / UseCase / Persona / Constraint` から選択

3. **関係マップ (文章で OK)**  
   - 主要エンティティ間の「所有」「依存」「発生源→結果」関係を箇条書き

4. **時系列イベント例 (最大 5)**  
   ```mermaid
   sequenceDiagram
       participant Actor
       participant System
       ...
   ```

5. **未解決の疑問点**  
   - 「<用語 or 行番号> が何を指すのか不明」のように列挙

6. **JSON 版 (機械処理用)**  
   ```json
   {
     "summary": "...",
     "terms": [
       { "type": "Entity", "name": "??", "aliases": ["??"], "attributes": ["??"], "source": "docA p.12" },
       ...
     ],
     "relations": [
       { "from": "Order", "to": "Customer", "relation": "belongsTo" }
     ],
     "events": ["Ordered", "Paid", "Shipped"],
     "open_questions": ["..."]
   }
   ```

【抽出アルゴリズムの手順】  
1. **前処理**：改行・ページ番号を保持したままクリーニング。  
2. **キーフレーズ抽出**：統計＋意味埋め込みで TF-IDF 上位 5% を候補に。  
3. **クラスタリング**：Sentence-BERT で類似度クラスタリングし、代表語を決定。  
4. **DDD タグ付け**：  
   - 「ID / 登録番号 / コード」が付帯 → Entity 候補  
   - 「～された」受動形動詞やビジネスルール → DomainEvent 候補  
5. **信頼度スコアリング**：  
   - 出現頻度 × コンテキスト一貫性で 0-1 を算出し 0.8 未満は「?」を付加。  
6. **フォーマット整形**：上記出力フォーマットへマッピング。

【制約】  
- 表記ゆれはカッコ書きで別名を保持（例: 顧客(Customer)）。  
- 自信が 80% 未満の抽出結果には末尾に「?」。  
- JSON 部分は **strict モード** でダブルクォートのみ使用し、改行不可。

【読みやすさガイド】  
- Markdown 内の表は 120 文字以内で改行。  
- 長い名称は `...` で省略してもよいが JSON 側はフル名称を保持。
```

---

## 💡 使い方のポイント

1. **一次資料は “そのまま” 入れる**  
   - 変に短くまとめず全文を投入（モデルに長文処理余力がある前提）。  
2. **資料セットが大きい場合**  
   - まず 1 資料ずつ投げて「terms」だけ取得 → 全資料をまとめて再投入しマージさせると精度が上がる。  
3. **フィードバックループ**  
   - JSON をスプレッドシートに貼り、チームでレビュー → 修正点を “追加入力” として再プロンプトするとユビキタス言語が洗練。  
4. **音声からのノイズ除去**  
   - 「あー」「えー」などフィラーは音声認識段階で削除しておくとタグ精度が向上。  
5. **RAG 併用**  
   - PDF が数百ページの場合は RAG でページレベル検索 → 抽出語を再帰的に深掘り、LLM のトークン消費を節約。  

---

## 🚀 さらに精度を高めたいとき

- **Few-shot 例示**  
  - 直近プロジェクトで正しく抽出できた “用語リスト＋JSON” を先頭に置き、モデルに期待出力を強く学習させる。  
- **マルチパス推論 (Chain-of-Density)**  
  - 同じプロンプトを温度違いで 3 回呼び、結果をエンサンブル平均 → 抽出漏れを減らす。  
- **追加メタデータ**  
  - 資料ごとに “document_id”, “page_no” をタグ付けし、あとから原典に戻りやすくする。  
